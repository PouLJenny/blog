# 微调

## 全量微调 (Full Fine-tuning)


## 参数高效微调 (PEFT - Parameter-Efficient Fine-Tuning)
- LoRA (Low-Rank Adaptation)： * 原理： 冻结模型原有的参数，在旁边增加一个可以训练的“旁路矩阵”。

[github](https://github.com/hiyouga/LLaMA-Factory.git)
[官网](https://llamafactory.readthedocs.io/)




# EOF