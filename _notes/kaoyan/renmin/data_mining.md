# 海量数据挖掘

## 考点

PPT中的练习题需要重点过一下

1. 组件化思想中的5个组件
2. 频繁模式挖掘的定义 
    - 支持度  会算
    - 可信度，会算
    - 找频繁项集
3. Apriori算法过程 找频繁项集 和 关联规则
4. 序列模式 求子序列  支持度
5. 决策树算法
    - 求总商  添加属性的商  
    - 求信息增益
6. 朴素贝叶斯 必考
5. 支持向量机 ，概念性的东西，不会考计算
    - 为什么用最大边缘做优化目标
    - 为啥叫支持向量
6. 前向传播 会算输入输出 后向传播不要求
6. 卷积神经网络 卷积、池化计算 必考 
7. 聚类
    - 曼哈顿距离 计算比较简单 考试的概率比较大
    - 欧几里得距离
    - KMeans 课件中有例题 必考

## 题型

1. 算法题
2. 描述题 （简答题）
3. 没有 判断、选择、填空 

## 知识点

- 分类 + 回归
    - 决策树、贝叶斯、神经网络、SVM、KNN、逻辑回归
- 聚类分析
    - 基于距离、基于密度、基于模型、基于层次、基于网络
- 推荐系统
    - 协同过滤、基于内容、基于知识、混合推荐、社会推荐
- 异常检测
    - 基于分布、基于深度、基于距离、基于密度
- 频繁模式
    - 频繁集合、频繁序列、频繁子图 


### 什么是数据挖掘

数据挖掘是从大量、不完全、有噪声、模糊、随机的数据中，提取隐含在其中人们事先不知道但又是潜在有用的信息和知识的过程。


### 数据挖掘算法的组件化思想

1. 学习任务
1. **模型（或模式）结构**
1. **评分函数（损失函数、Loss函数）**
1. **搜索和优化方法**
1. 数据管理策略


数据挖掘算法的设计过程： 
1. 确定数据挖掘任务
    1. 确定是一个回归任务还是分类任务
    1. 当被预测的变量是范畴型(category)时，称之为分类
    1. 当被预测的变量是数量型(quantitative)时，称之为回归
1. 确定模型结构
    1. 通过学习所得到的知识通常称为模型(Model)或者是模式(Pattern)，例如：
        1. 线性回归模型
        1. 决策树模型
        1. 支持向量机模型
        1. 层次聚类模型
        1. 频繁序列模式
        1. 等等
    1. 模型是对整个数据集的高层次全局性的描述或总结
        1. 模型可以将数据集中的每个对象分配到某聚类中
    1. 模型是对现实世界的抽象描述
    1. 模式是局部的，它仅对一小部分数据做出描述
        1. 例如： 购买商品A和B的人也可能经常购买C
    1. 模式有可能只支持几个对象或对象的几个属性
    1. 全局的模型和局部的模式是相互联系的，就好比一个硬币的两个面
        1. 例如： 为了检测出数据集内的异常对象（局部模式），需要一种对数据集内正常对象的描述(全局模式).
1. 确定评分函数
    1. 有了模型（模式）的结构之后，接下来的任务就是要根据数据集为模型（模式）的结构选择合适的参数，即将结构拟合到数据
    1. 由于模型（模式）的结构代表的是函数的一般形式，它的参数空间非常大，可选的参数值有很多。那么什么样的参数值比较好呢，需要一个评价指标，这个评价指标就是评分函数
    1. 评分函数用来对数据集与模型（模式）结构的拟合程度进行评估
    1. 如果没有评分函数，就无法说出一个特定的已拟合的模型是否比另一个好。或者说，就没有办法为模型（模式）选择出一套好的参数值来
    1. 也叫损失函数(Loss)、代价函数、目标函数、优化函数、优化目标等等。
    1. 常用的评分函数有：
        1. 似然函数(Likelihood)
        1. 均方误差（MSE）
        1. 准确率(Accuracy)
        1. 交叉熵（Cross Entropy）
        1. ...
1. 确定优化方法
    1. 搜索优化的目标是确定模型（模式）的结构及其参数值，以使评分函数达到最大值或最小值
        1. 均方误差最小
        1. 准确率最高
        1. 似然最大
        1. ...
    1. 常用的优化方法： 
        1. 爬山（Hill-Climing）
        1. 最陡峭下降(Steepest-Descend)
        1. 期望最大化（Expectation-Maximization,EM）
        1. ...
    1. 常用的搜索方法
        1. 贪婪搜索
        1. 分支界定法
        1. 广度(深度)优先搜索
        1. ...
1. 确定数据管理策略

### 数据挖掘的特点

1. 数据源必须是真实的。数据挖掘所处理的数据通常是已存在的真实数据，而不是为了进行数据分析而专门收集的数据。
2. 处理的数据必须是海量的。
3. 查询一般是决策制定者提出的随机查询
4. 挖掘出来的知识一般是不可预知的

### KDD

Knowledge Discovery from Data,从数据中发现知识

### KDD的主要步骤

1. 数据集成： 主要指将多种数据源组合在一起
2. 数据清理： 消除噪声或不一致的数据
3. 数据选择： 从数据库中提取（与分析任务）相关的数据的过程
4. 数据转换： 通过汇总、聚集、降低维数等数据转换方法将数据统一成适合挖掘的形式，减少数据量，降低数据的复杂性
5. 数据挖掘： 确定挖掘任务，选择合适的工具，进行挖掘知识的操作
6. 模式评估： 根据用户提供的指标，对挖掘出来的模式（pattern）进行评估的过程
7. 知识表示： 主要指使用可视化和知识表示技术，向用户提供容易理解的挖掘到的知识。

### 数据库系统或数据仓库系统的工具层有几类？

1. 以管理信息系统为代表的查询报表类工具
2. 以OLAP为代表的验证型工具
3. 以数据挖掘为代表的挖掘型工具

### 数据挖掘的分类

1. 根据挖掘的数据库类型
    - 关系的
    - 对象的
    - 关系-对象
    - 空间
    - 时间
    - 文本
    - 多媒体
    - web数据

2. 知识类型
    - 特征
    - 关联
    - 分类
    - 聚类
    - 异常点
    - 趋势和演化
    - 偏差
    - 类似性

3. 所有的技术类型
    - 用户交互程度
        - 自动系统
        - 交互探查系统
        - 查询驱动系统
    - 数据分析方法
        - 面向数据库或数据仓库
        - 机器学习
        - 统计
        - 可视化
        - 模式识别
        - 神经网络

4. 应用领域
    - 财政
    - 电信
    - DNA
    - 股票市场

### 数据挖掘算法的组件化思想

1. 模型或模式结构
    通过数据挖掘所得到的知识通常称为模型或模式。例如线性回归模型、层次聚类模型、频繁序列模式等
2. 数据挖掘任务
    - 模式挖掘
        从数据中寻找模式，如寻找**频繁模式**等
    - 预测建模
        根据现有的数据先建立一个模型，然后应用这个模型来对未来的数据进行预测，当被预测的变量是范畴（category）时，称为**分类**;当被预测的变量是数量（quantitative）时，称为**回归**.
    - 描述建模
        描述数据的全局特征。描述和预测的关键区别是预测的目标是唯一的变量，而描述并不以单一的变量为中心。描述建模的典型例子是**聚类**分析。聚类分析是根据某种相似性度量函数将一批数据（对象）分成若干组，使得同一组中的数据足够相似、不同组中的数据足够不相似的过程。与分类不同，聚类是一个无监督学习的过程。
3. 评分函数
    由于模型（模式）代表的是函数的一般形式，它的参数空间非常大，可选的参数值有很多。这就需要一个评价指标来决定选择什么样的参数比较好，这个评价指标就是评分函数。评分函数用来对数据集与模型（模式）的拟合程度进行评估。 常用的评分函数有，似然（likelihood）函数、误差平方和、准确率、交叉商等。
4. 搜索和优化方法
    搜索和优化的目标确定模型（模式）的结构及其参数值，以使评分函数达到最小值（最大值）。
    针对特定的模型，发现其参数值的过程称为**优化**问题.常用的方法有，爬山、梯度下降、最大期望等。
    针对潜在的模型（模式）族中发现最佳模型（模式）结构的过程通常被称为**搜索**问题，常用的方法有，贪婪算法、分支限界法、广度（深度）优先搜索。

5. 数据管理策略

    传统的统计和机器学习算法都假定数据是可以全部放入内存的，所以不太关心数据管理技术。对于数据挖掘来说动辄就是GB、TB甚至PB的数据，放在内存中是不现实的。因此，针对海量数据应设计有效的**数据组织**和**索引技术**，或着通过**采样**、**近似**等手段来减少数据的扫描次数，从而提高数据挖掘算法的效率。


实际应用时应按照
2 -> 1 -> 3 -> 4 -> 5


### 频繁模式挖掘

### 关联规则的分类

1. 规则中所处理数据的类型
    - 布尔关联规则， 又叫二值关联规则
    - 量化关联规则 
2. 涉及的数据维度
    - 单维关联规则
    - 多维关联规则
        - 维间关联规则
        - 混合维关联规则
3. 规则中数据的抽象层次
    - 单层关联规则
    - 多层关联规则
4. 其他
    - 对关联规则施加语义约束，限制规则左边和右边必须包含哪些部分

### 序列数据库

序列数据库（sequence database） 是指包含了一系列有序事件的数据库，这些事件发生的具体时间不重要，但事件发生的先后顺序却非常关键。


### 决策树算法

本质上就是选择树根的过程

1. 选择属性，作为树根
    比较流行的方法，信息增益方法，信息增益最大的属性被认为是最好的树根
2. 

### 熵

熵来表示信息的不确定性

### 信息

信息用来消除不确定性


### 贝叶斯公式- 贝叶斯分类

P(B|A) = P(AB) / P(A)

P(A|B) = P(AB) / P(B) 

上述两个公式合并，可以得到:

P(B|A) = P(AB) / P(A) = (P(AB) / P(B)) * P(B) / P(A) = P(A|B) * P(B) / P(A) 

### 贝叶斯分类 - 拉普拉斯修正

### 支持向量机 SVM

Support Vector Machine

是一类按有监督学习方式对数据进行分类的广义线性分类器，其决策边界是对学习样本求解的最大边距超平面


### Support Vectors

Support Vectors are those data points that the margin pushes up against;


### 神经网络分类方法

- 神经网络
- 深度神经网络 
- 卷积神经网络 CNN
- 循环神经网络 RNN
- 深度信念网络 DBN
- k-Nearest Neighbors KNN



### 机器学习

传统的机器学习是通过领域专家来建模，然后调整参数的。

### 深度学习

深度学习是机器学习的子领域。

深度学习是指在多层神经网络上运用各种机器学习算法解决图像、文本等各种问题的算法集合

深度学习从大类上可以归入神经网络，不过在具体实现上有许多变化

深度学习的核心是特征学习，旨在通过分层网络获取分层次的特征信息，从而解决以往需要人工设计特征的重要难题。


### 神经网络适合什么样的数据

1. 数据量比较小，缺少足够的样本建立模型，
2. 数据的结构难以用传统的统计方法来描述
3. 分类模型难以表示为传统的统计模型


### 神经网络的缺点

1. 需要很长的训练时间，因而对于有足够长训练时间的应用更合适
2. 需要大量的参数，这些通常主要靠经验确定，如果网络拓扑或“结构”
3. 可解释性差，这种特点使得其在数据挖掘的初期非常不被看好

### 神经网路的优点

1. 分类的准确度高
2. 并行分布处理能力强
3. 分布存储及学习能力高
4. 对噪音数据有很强的鲁棒性和容错能力


### 后向传播算法

在多路前馈神经网络上学习

- 向前传播输入
- 反向传播误差


### 人类视觉原理

1981年诺贝尔医学奖，颁发给了 “发现了视觉系统的信息处理” ，可视皮层是分级的。

### 卷积神经网络 CNN

模仿人类大脑的这个特点，构造多层神经网络，较低层的识别初级的图像特征，若干底层特征组成更上一层特征，
最终通过多个层级的组合，在顶层做出分类。

是一种特殊的神经网络算法，用卷积思想替代神经网络里面的矩阵乘法思想

擅长处理图像，特别是大图像的相关机器学习的问题。

核心就是通过 卷积 + 池化的思想

由卷积层 + 池化层 + 全链接层组成，其中卷积层 + 池化层构成多个卷积组


### 聚类分析

将数据自发的分成不同的分组，对应各种不同的类别

### 评价一个聚类方法好坏的指标

- 可伸缩性
- 能够处理各种不同类型的数据
- 能够发现任意形状的聚类
- 在决定输入参数的时候，对领域知识的需求要小
- 能够处理噪声和异常点
- 对输入数据的顺序部敏感
- 可以处理高维数据
- 可以和用户制定的限定条件相结合
- 可解释性和使用性好
 

 ### 计算对象之间的距离

 - 明考斯基距离
 - 曼哈顿距离
 - 欧几里得距离

 ### K-Means 聚类方法步骤

 1. 给k个Cluster选定最初的中心点，称为k个means
 2. 计算每个对象和每个中心点之间的距离
 3. 把每个对象分配给距它最近的中心点做属的cluster
 4. 重新计算每个cluster的中心点
 5. 重复2，3，4步，直到算法收敛
   

# EOF