# 缓存应用

## 大型缓存全量更新问题

1. 网络耗费的资源大
2. 每次对redis都存取大数据，对redis的压力也比较大
3. 大家记不记得，之前我给大家提过，redis的性能和吞吐量能够支撑到多大，基本跟数据本身的大小有很大的关系

如果数据越大，那么可能导致redis的吞吐量就会急剧下降

缓存维度化解决方案
维度：商品维度，商品分类维度，商品店铺维度




## 缓存的经典问题

### 缓存雪崩
**(1) 是什么**

一段时间内本应在redis缓存中处理的大量请求，都发送到了数据库进行处理，导致对数据库的压力迅速增大，严重时甚至可能导致数据库崩溃，从而导致整个系统崩溃，就像雪崩一样，引发连锁效应，所以叫缓存雪崩。

**(2) 为什么**

出现上述情况的常见原因主要有以下两点：
1. 大量缓存数据同时过期，导致本应请求到缓存的需重新从数据库中获取数据。
2. redis本身出现故障，无法处理请求，那自然会再请求到数据库那里。

**(3) 怎么办**

针对大量缓存数据同时过期的情况：
1. 实际设置过期时间时，应当尽量避免大量key同时过期的场景，如果真的有，那就通过随机、微调、均匀设置等方式设置过期时间，从而避免同一时间过期。
2. 添加互斥锁，使得构建缓存的操作不会在同一时间进行。
3. 双key策略，主key是原始缓存，备key为拷贝缓存，主key失效时，可以访问备key，主key缓存失效时间设置为短期，备key设置为长期。
4. 后台更新缓存策略，采用定时任务或者消息队列的方式进行redis缓存更新或移除等。

针对redis本身出现故障的情况：
1. 事前，在预防层面，可以通过主从节点的方式构建高可用的集群，也就是实现主Redis实例挂掉后，能有其他从库快速切换为主库，继续提供服务。redis集群的多机房部署，主从尽量分布在不同的机房。
2. 事中，如果事情已经发生了，那就要为了防止数据库被大量的请求搞崩溃，可以采用服务熔断或者请求限流的方法。当然服务熔断相对粗暴一些，停止服务直到redis服务恢复，请求限流相对温和一些，保证一些请求可以处理，不是一刀切，不过还是看具体业务情况选择合适的处理方案。多级缓存本地缓存还能撑一部分流量。
3. 事后，对redis数据做恢复，有备份文件用备份文件，没有的话就快速预热，把热点key先刷进去，赶紧把redis启动起来

### 缓存击穿

**(1) 是什么**
缓存击穿一般出现在高并发系统中，是大量并发用户同时请求到缓存中没有但数据库中有的数据，也就是同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。

**(2) 为什么**
这种情况其实一般出现的原因就是某个热点数据缓存过期，由于是热点数据，请求并发量又大，所以过期的时候还是会有大量请求同时过来，来不及更新缓存就全部打到数据库那边了。

**(3) 怎么办**
针对这种情况有两种常见的处理方案：

1. 简单粗暴的对热点数据不设置过期时间，这样不会过期，自然也就不会出现上述情况了，如果后续想清理，可以通过后台进行清理。
2. 添加互斥锁，即当过期之后，除了请求过来的第一个查询的请求可以获取到锁请求到数据库，并再次更新到缓存中，其他的会被阻塞住，直到锁被释放，同时新的缓存也被更新上去了，后续请求又会请求到缓存上，这样就不会出现缓存击穿了。
3. 定期主动的刷新热点缓存

### 缓存穿透

**(1) 是什么**

缓存穿透是指数据既不在redis中，也不在数据库中，这样就导致每次请求过来的时候，在缓存中找不到对应key之后，每次都还要去数据库再查询一遍，发现数据库也没有，相当于进行了两次无用的查询。这样请求就可以绕过缓存直接查数据库，如果这个时候有人想恶意攻击系统，就可以故意使用空值或者其他不存在的值进行频繁请求，那么就会对数据库造成比较大的压力。

**(2) 为什么**

这种现象的原因其实很好理解，业务逻辑里面如果用户对某些信息还没有进行相应的操作或者处理，那对应的存放信息的数据库或者缓存中自然也就没有相应的数据，也就容易出现上述问题。

**(3) 怎么办**

针对缓存穿透，一般有以下三种处理方案：

1. 非法请求的限制，主要是指参数校验、鉴权校验等，从而一开始就把大量的非法请求拦截在外，这在实际业务开发中是必要的手段。
2. id字段对外展示的时候加密，数据库一般是自增的id，与前端交互的时候用加密的id值，不可预测。
3. 缓存空值或者默认值，如果从缓存取不到的数据，在数据库中也没有取到，那我们仍然把这个空结果进行缓存，同时设置一个较短的过期时间。通过这个设置的默认值存放到缓存，这样第二次到缓存中获取就有值了，而不会继续访问数据库，可以防止有大量恶意请求是反复用同一个key进行攻击。
4. 使用布隆过滤器快速判断数据是否存在。那什么是布隆过滤器呢，
简单来说，就是可以引入了多个相互独立的哈希函数，保证在给定的空间和误判率下，完成元素判重。
因为我们知道，存在hash碰撞这样一种情况，那如果只使用一个hash函数，则碰撞冲突的概率明显会变大，那为了减少这种冲突，我们可以多引入几个hash函数，而布隆过滤器算法的核心思想就是利用多个不同的hash函数来解决这样一种冲突。它的优点是空间效率高，查询时间短，远超其他算法，而它的缺点就是会存在一定的误识别率，它不能完全保证请求过来的key，通过布隆过滤器的校验，就一定有这个数据，毕竟理论上还是会存在冲突情况，无论概率多小。
但是，只要没有通过布隆过滤器的校验，那么这个key就一定不存在，只要利用这一点其实就已经可以过滤掉大部分不存在的key的请求了，在正常场景下已然足够了。


除了上述三种常见的Redis缓存异常问题之外，还经常听到的有缓存预热和缓存降级两个名词，与其说是异常问题，不如说是两种的优化处理方法。

### 缓存预热

缓存预热就是系统上线前后，将相关的缓存数据直接加载到缓存系统中去，而不依赖用户。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题。用户直接查询事先被预热的缓存数据，这样可以避免那么系统上线初期，对于高并发的流量，都会访问到数据库中， 对数据库造成流量的压力。根据数据不同量级，可以有以下几种做法：

- 数据量不大：项目启动的时候自动进行加载。
- 数据量较大：后台定时刷新缓存。
- 数据量极大：只针对热点数据进行预加载缓存操作。

### 缓存降级

缓存降级是指当缓存失效或缓存服务出现问题时，为了防止缓存服务故障，导致数据库跟着一起发生雪崩问题，所以也不去访问数据库，但因为一些原因，仍然想要保证服务还是基本可用的，虽然肯定会是有损服务。因此，对于不重要的缓存数据，我们可以采取服务降级策略。一般做法有以下两种：

- 直接访问内存部分的数据缓存。
- 直接返回系统设置的默认值。


### 数据库缓存一致性问题

[非常棒的博客](http://kaito-kidd.com/2021/09/08/how-to-keep-cache-and-consistency-of-db/ )

1. 最开始 application --------> db
刚开始业务量少，并发低

2. application -------> db
               -------> cache
随着业务量多，复杂，并发上来， 通过加缓存的方式可以以高性价比的方式提升系统的吞吐量
这种，情况下就会引入一个问题，缓存和数据库一致性的问题
  1. 首先确定一致性的目标
      - 强一致性
      - 最终一致性
  2. 强一致性
      - 在现实的分布式系统中，实现强一致性是非常难的，在追求强一致性的过程中会极大的牺牲系统的性能
      - 2PC/3PC
      - 使用分布式锁
      - 如果需要极高的一致性，可以通过将操作路由到同一个队列中，强制执行串行化

一般互联网应用对系统的性能要求都很高，所以大部分都是采用的最终一致性方案，并尽可能的向强一致性方向靠拢

最终一致性解决方案：

1. 定时全量同步数据库数据到cache中
优点： 
  - 实现简单
  - 缓存命中率高
缺点：
  - 数据库和缓存之间的会出现一段时间的不一致
  - 缓存利用率低，造成很大的缓存数据浪费

2. 只缓存请求的数据，并设置失效时间

方案：
  - 写请求只更新数据库
  - 读请求先读缓存，如果缓存没有数据则读数据库，并把数据库的值写入到缓存中，并设置失效时间

优点：
  - 缓存利用率高，不经常访问的数据会随着时间被淘汰
缺点：
  - 还是会有数据库缓存不一致的问题

场景就是有一次读，一次写，一次读请求：
第一次，读请求： 缓存没数据，读数据库，并写入缓存，设置超时时间
第二次（缓存还没失效），写请求： 只更新了数据库，缓存并没有更新
第三次 (缓存还没失效), 读请求： 读到的还是缓存中的旧数据

3. 只缓存请求的数据，并设置失效时间,写数据同时更新缓存

上面的方案还是没解决数据一致性的问题。

这里面需要引入一种机制来保证就是： 数据写入数据库的同时更新缓存

这里面方案有两种：
- 先更新缓存，后更新数据库
- 先更新数据库，后更新缓存

因为操作被分成了两步，那么每一步都可能成功或者失败
- 如果第一步失败了，整个请求就直接failfast倒是问题不大
- 如果第一步成功了，第二步失败了，就比较麻烦，不管是谁先谁后，都是有问题的
- 那么如果是两步都成功了呢？看似皆大欢喜，但是我们还有一个因素没有考虑**并发**，加入这个因素之后就不一样了，假设有下面一个场景：

使用 「先更新数据库，再更新缓存」的方案为例子

线程T1, 更新数据库 值为V1
线程T2, 更新数据库 值为V2
线程T2, 更新缓存值 为V2
线程T1, 更新缓存值 为V1

数据库最终的值是线程T2更新的V2，但是缓存的值最终为T1更新的V1，并发情况下不同的线程执行的两步有时间差，所以会出现问题

怎么解决这个问题呢，针对同一个业务主键让执行顺序串行化，但就算是解决了并发的问题，还是没解决第二步失败的问题，而且串行导致了性能的下降


4. 只缓存请求的数据，并设置失效时间,写数据同时删除缓存

上述方案中的更新缓存，改成删除缓存，这样两步分别是

- 删除缓存，更新数据库
- 更新数据库，删除缓存

先不考虑并发， 第二步失败的情况

- 删除缓存成功，更新数据库失败，没问题，下次查询直接查数据库更新缓存就行
- 更新数据库成功，删除缓存失败，就有问题了，下次查询的有可能是旧的数据

两步都成功的情况，引入并发因素：

第一种情况： 删除缓存，更新数据库

线程T1，删除缓存

线程T2，读取数据，
线程T2, 发现缓存没有数据，读取数据库获取值V0
线程T2, 把读取到的值V0写入到缓存

线程T1，更新数据库值为V1

第二种情况：更新数据库，删除缓存

线程T2，读取数据，
线程T2, 发现缓存没有数据，读取数据库获取值V0

线程T1，更新数据库值为V1
线程T1，删除缓存，

线程T2, 把读取到的值V0写入到缓存

第二种情况是理论上可能发生的，这里在讨论的过程中，我们再引入一个因素**概率**，讨论概率，我们先分析问题发生的条件
第二种情况发生的条件：
- 1、缓存没有数据
- 2、读请求 + 写请求并发
- 3、更新数据库的动作比查询数据库的动作快

可想而之，第3个条件的概率是非常低的，因为写数据库需要加锁，更新索引等，比查询更复杂，应该更慢才对。
基于低概率的条件，方案 「先更新数据库，再删除缓存」 基本满足了数据一致性。

但是还有个问题，就是第二步失败的问题。
现在问题就剩下了，解决第二步失败的问题，这里其实能想到的解决办法就是：
**重试**
但是也不能无脑的重试

失败后**立即**重试，会面临的问题：
- 重试失败的概率非常高
- 重试多少次比较合理？
- 重试会一直占用线程资源，无法服务其他请求

这里能看到这种**同步重试**的方案，并不是特别严谨，

我们进而想到了异步重试的方式：通过消息队列，来保证异步消息的可靠传输，

这里有个概率的问题，操作redis和发送mq同时失败的概率是非常低的，这里最终的方案应该是

- 更新数据库
- 删除redis
- 如果删除redis失败，则触发异步重试的机制

但是，上面的方案还是有问题的， 因为非原子性操作，如果执行到某个步骤，机器突然挂了，按理来说这种概率也很小才对。

所以还有第二种异步重试方式： 通过监听binlog日志来实现， + canal/开源的消息监听组件 + mq 来删除redis
我个人认为这种方式当前看是最靠谱的了，他能避免一个极端的case，就是如果服务端完成更新数据库之后就挂了，后面的步骤没办法执行，导致的缓存数据库不一致的问题。

下面再引入一个变量来分析问题，读写分离架构下的**主从复制延迟**，这就会有一种场景：

更新数据库，删除缓存方案：

线程T1，更新master数据库值为V1
线程T1，删除缓存，
线程T2，读取数据，
线程T2, 发现缓存没有数据，读取slaver数据库获取值V0
master数据库同步数据到slaver完成
线程T2, 把读取到的值V0写入到缓存

这里问题的本质就是数据库主从同步的延迟，导致从库延迟的数据同步没有更新到redis上。
解决这种情况的方案就是使用延迟删，或者是使用canal监听从库的变更


所谓延迟双删，就是更新完数据库后，删除缓存，延迟一定时间保证从库同步完成后再删除一次



## 一些常用的缓存框架
